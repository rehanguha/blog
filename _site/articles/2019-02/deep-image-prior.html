<!DOCTYPE html>
<html lang="en">




<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="Deep Image Prior is a type of convolutional neural network used to enhance a given image with no prior training data other than the image itself.">
  <meta name="keywords" content="Rehan, R. Guha, Joel, Machine Learning, and Resume">
  <meta name="author" content="Brief :: Deep Image Prior | Portfolio &amp; Blog">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="theme-color" content="#f5f5f5">

  <!-- Twitter Tags -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Brief :: Deep Image Prior | Portfolio &amp; Blog">
  <meta name="twitter:description" content="Deep Image Prior is a type of convolutional neural network used to enhance a given image with no prior training data other than the image itself.">
  
    <meta property="twitter:image" content="http://localhost:4000/img/leonids-logo.png">
  

  <!-- Open Graph Tags -->
  <meta property="og:type" content="blog">
  <meta property="og:url" content="http://localhost:4000/articles/2019-02/deep-image-prior">
  <meta property="og:title" content="Brief :: Deep Image Prior | Portfolio &amp; Blog">
  <meta property="og:description" content="Deep Image Prior is a type of convolutional neural network used to enhance a given image with no prior training data other than the image itself.">
  
    <meta property="og:image" content="http://localhost:4000/img/leonids-logo.png">
  
  <title>Brief :: Deep Image Prior | Portfolio & Blog</title>

  <!-- CSS files -->
  <link rel="stylesheet" href="http://localhost:4000/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">

  <link rel="canonical" href="http://localhost:4000/articles/2019-02/deep-image-prior">
  <link rel="alternate" type="application/rss+xml" title="Portfolio &amp; Blog" href="http://localhost:4000/feed.xml" />

  <!-- Icons -->
  <!-- 16x16 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
  <!-- 32x32 -->
  <link rel="shortcut icon" href="http://localhost:4000/favicon.png">
</head>

<body>
  <div class="row">
    <div class="col s12 m3">
      <div class="table cover">
        

<div class="cover-card table-cell table-middle">
  
  <a href="http://localhost:4000/">
    <img src="http://localhost:4000/img/profile_photo.jpg" alt="" class="avatar">
  </a>
  
  <a href="http://localhost:4000/" class="author_name">Rehan Guha</a>
  <span class="author_job">Data Scientist & Machine Learning Engineer</span>
  <span class="author_bio mbm"></span>
  <nav class="nav">
    <ul class="nav-list">
      <li class="nav-item">
        <a href="http://localhost:4000/">home</a>
      </li>
       
      <li class="nav-item">
        <a href="http://localhost:4000/archive/">Archive</a>
      </li>
          
      <li class="nav-item">
        <a href="http://localhost:4000/categories/">Categories</a>
      </li>
            
      <li class="nav-item">
        <a href="http://localhost:4000/resume/">Resume</a>
      </li>
        
      <li class="nav-item">
        <a href="http://localhost:4000/tags/">Tags</a>
      </li>
         
    </ul>
  </nav>
  <script type="text/javascript">
  // based on http://stackoverflow.com/a/10300743/280842
  function gen_mail_to_link(hs, subject) {
    var lhs,rhs;
    var p = hs.split('@');
    lhs = p[0];
    rhs = p[1];
    document.write("<a class=\"social-link-item\" target=\"_blank\" href=\"mailto");
    document.write(":" + lhs + "@");
    document.write(rhs + "?subject=" + subject + "\"><i class=\"fa fa-fw fa-envelope\"></i><\/a>");
  }
</script>
<div class="social-links">
  <ul>
    
    <li><a href="http://twitter.com/rehan_guha" class="social-link-item" target="_blank"><i class="fa fa-fw fa-twitter"></i></a></li>
    <li><a href="http://facebook.com/rehanguhajoel" class="social-link-item" target="_blank"><i class="fa fa-fw fa-facebook"></i></a></li>
    
    <li><a href="http://linkedin.com/in/rehanguha" class="social-link-item" target="_blank"><i class="fa fa-fw fa-linkedin"></i></a></li>
    
    
    
    
    <li><a href="http://github.com/rehanguha" class="social-link-item" target="_blank"><i class="fa fa-fw fa-github"></i></a></li>
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
  </ul>
</div>

</div>

      </div>
    </div>
    <div class="col s12 m9">
      <div class="post-listing">
        

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-AMS-MML_HTMLorMML,https://rehanguha.github.io/js/MathJaxLocal.js">
</script>




<a class="btn" href= "http://localhost:4000/" >
  Home
</a>



<div id="post">
  <header class="post-header">
    <h1 title="Brief :: Deep Image Prior">Brief :: Deep Image Prior</h1>
    <span class="post-meta">
      <span class="post-date">
        15 FEB 2019
      </span>
      •
      <span class="read-time" title="Estimated read time">
  
  
    6 mins read
  
</span>

    </span>

  </header>

  <article class="post-content">
    <p>Deep Image Prior defies the idea that “deep learning only works in the context of massive datasets or models pretrained on such datasets”. 
This paper showed that some deep neural networks could be successfully trained on a single image without large datasets, the structure of the network itself could be preventing deep networks from overfitting.</p>

<h3 id="overview">Overview</h3>

<p>“Deep Image Prior” a startling paper showing that the  <strong>structure</strong>  of the convolutional neural network (CNN) contains sufficient “knowledge” of natural images. It showed that some tasks – such as denoising and super-resolution – can actually be successfully conducted on a  <strong>single image</strong> ,  <strong>without any additional training data</strong>.</p>

<p>This post is a digest of the paper, rather than a comprehensive summary.</p>

<h3 id="from-the-deep-image-prior-author">From the “Deep Image Prior” Author</h3>

<h3 id="brief-explanation-of-how-it-works">Brief Explanation of “How it Works?”</h3>

<p>A prior is short for “prior distribution”, which is intuitively a distribution that represents our basic beliefs in the absence of information.</p>

<p>In the case of images, a prior distribution over images basically represents what we think ground truth images should look like. Consider the following two images:</p>

<p><img src="Picture1.png" alt="Picture" />The left image is random noise and the right image is a cat.</p>

<p>This may seem too obvious to mention, but from the perspective of a computer, both are just arrays of integers. The fact that we recognize one as a natural image and the other as noise indicates that humans have some implicit prior over what natural images should look like.
Priors are used in generative models to ensure that we gain “natural” outputs. In the context of image generation, priors restrict the output image to resemble natural images instead of noise.</p>

<p>Regularizers can often be interpreted as incorporations of prior distributions. For instance, l2 regularization represents a belief that weights should be zero on average, and larger weights should be exponentially rarer compared to smaller weights. This is equivalent to putting a Gaussian prior over the weights.
How are priors used in practice? Let’s take a practical example that is introduced in the paper: denoising an image. We will denote the noisy image as $x_0$ and the image we produce as $x$.</p>

<p><img src="Picture2.png" alt="Picture" />A noisy image (left) and its denoised, original version (right)</p>

<p>A straightforward approach to this problem would be to train a neural network that takes noisy images as input and outputs the denoised image. This is called a <strong>learning-based approach</strong>.</p>

<p>The problem with this is that, this approach requires massive amounts of noisy and Ground Truth image pairs.
Suppose now that we do not want to use any additional data.</p>

<p>How do we perform denoising in this scenario?</p>

<p>One approach is to think of this problem as an optimization problem. We aim to create an image $x$ that is both close to the noisy image $x$ but is “noise-free”, “clear” and “natural”.</p>

<table>
  <tbody>
    <tr>
      <td>We can measure the “closeness” of images with the l2 distance between the pixel values $</td>
      <td> </td>
      <td>x - x_0</td>
      <td> </td>
      <td>^2$.</td>
    </tr>
  </tbody>
</table>

<p>Suppose for a moment that there was a function that could measure the “naturalness” or “clearness” of an image $naturalness(x)$. For the sake of aligning the notation with the original paper, we will use the term $R(x) = - naturalness(x)$ for the remainder of this post. $R(X)$ measures the “unnaturalness” or “unclearness” of an image. In this case, our optimization objective would be</p>

<script type="math/tex; mode=display">min || x - x_0 ||^2 + R(x)</script>

<table>
  <tbody>
    <tr>
      <td>The left term $</td>
      <td> </td>
      <td>x – x_0</td>
      <td> </td>
      <td>^2$  pulls the term towards the original image, making sure that the image does not deviate too far. The right term pulls $x$ in the direction of natural images, (hopefully) reducing the noise.</td>
    </tr>
  </tbody>
</table>

<p>The term $R(x)$ represents our prior over natural images and is, therefore, a “regularization term”. Without the regularization term $R(x)$, the optimizer will “overfit” on the noisy image – i.e. it will just return the noisy image. Therefore, how we define this prior/regularization term is crucial in obtaining high-quality results.</p>

<p>Unfortunately, we do not have an exact prior over natural images. Traditionally, we have used hand-crafted features to represent the prior, but these always involve some level of arbitrariness. The essence of this paper is that CNNs can be used as priors over images; in other words, CNNs in some way “know” what natural images should and should not look like. The remainder of this post will explain how the paper has verified this statement and its explanation behind it.</p>

<p><strong>Randomly initialized</strong>  convolutional neural networks (CNNs) that are used to generate images have an implicit “prior”: they resist generating noisy images and have a bias towards natural images.
The idea of the paper is to get rid of the explicit regularization term and use a CNN “decoder-encoder” model to construct the output image $x$. Expressed as an equation, the optimization objective becomes</p>

<table>
  <tbody>
    <tr>
      <td>$min</td>
      <td> </td>
      <td>f_\theta (z) – x_0</td>
      <td> </td>
      <td>^2$</td>
    </tr>
  </tbody>
</table>

<p>where $\theta$ represents the parameters of the model and $z$ is a randomly initialized latent vector. Instead of directly optimizing $x$, we optimize $\theta$ using gradient descent. The surprising aspect of this paper is that we initialize $\theta$ randomly.
Using this property, we can train CNNs to conduct denoising, super-resolution, and a host of other tasks on a  <strong>single image</strong>.
When we optimize using gradient descent, CNNs “resist” noisy (unnatural) images, and has a bias towards producing natural images. The following figure provides evidence to support this claim:</p>

<p><img src="Picture3.png" alt="Picture" /></p>

<h3 id="application">Application</h3>

<h5 id="1-denoising-and-general-reconstruction">1. Denoising and general reconstruction</h5>
<p>Aside from simple additive noise, noise can come from all sorts of sources such as compression. The paper demonstrates the applicability of this method to a wide range of uses. Here is one example of successful denoising:
<img src="Picture4.png" alt="Picture" /></p>

<h5 id="2-super-resolution">2. Super-resolution</h5>
<p>The goal of super resolution is to take a low-resolution image and up sample it to create a high-resolution version. The following are some results from the paper:
<img src="Picture5.png" alt="Picture" /></p>

<h5 id="3-inpainting">3. Inpainting</h5>
<p>Inpainting is a task where some of the pixels in an image are replaced with a blank mask, and the erased portion has to be reconstructed. In this case, the pixels corresponding to the blank mask are excluded from the loss function, meaning we need some prior to determine how the blank pixels will be filled in.
<img src="Picture6.png" alt="Picture" /></p>

<h3 id="references">References</h3>

<ol>
  <li>https://dmitryulyanov.github.io/deep_image_prior</li>
  <li>https://en.wikipedia.org/wiki/Deep_Image_Prior</li>
</ol>

<p>Read more @ <a href="https://labs.imaginea.com/post/deep-image-prior/">Imaginea Labs Blog</a></p>

  </article>
</div>

<div class="share-buttons">
  <h6>Share on: </h6>
  <ul>
    <li>
      <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/articles/2019-02/deep-image-prior" class="twitter btn" title="Share on Twitter"><i class="fa fa-twitter"></i><span> Twitter</span></a>
    </li>
    <li>
      <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/articles/2019-02/deep-image-prior" class="facebook btn" title="Share on Facebook"><i class="fa fa-facebook"></i><span> Facebook</span></a>
    </li>
    <li>
      <a href="https://plus.google.com/share?url=http://localhost:4000/articles/2019-02/deep-image-prior" class="google-plus btn" title="Share on Google Plus"><i class="fa fa-google-plus"></i><span> Google+</span></a>
    </li>
    <li>
      <a href="https://news.ycombinator.com/submitlink?u=http://localhost:4000/articles/2019-02/deep-image-prior" class="hacker-news btn" title="Share on Hacker News"><i class="fa fa-hacker-news"></i><span> Hacker News</span></a>
    </li>
    <li>
      <a href="https://www.reddit.com/submit?url=http://localhost:4000/articles/2019-02/deep-image-prior" class="reddit btn" title="Share on Reddit"><i class="fa fa-reddit"></i><span> Reddit</span></a>
    </li>
  </ul>
</div><!-- end share-buttons -->


<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES * * */
    var disqus_shortname = 'rehanguha';

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>



        <footer>
  &copy; 2019 Rehan Guha.
</footer>

      </div>
    </div>
  </div>
  <script type="text/javascript" src="http://localhost:4000/js/jquery-3.2.1.min.js"></script>
<script type="text/javascript" src="http://localhost:4000/js/main.js"></script>

<!-- Asynchronous Google Analytics snippet -->
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-134752950-1', 'auto');
  ga('send', 'pageview');
</script>



</body>
</html>
